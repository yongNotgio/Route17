{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Route25 Dataset - Scrape Iloilo Jeepney Route Index\n",
        "\n",
        "        This notebook scrapes the public route compilation page:\n",
        "        `https://shemaegomez.com/iloilo-city-jeepney-routes/`\n",
        "\n",
        "        It exports:\n",
        "        - `output/iloilo_routes_index.json`\n",
        "        - `output/iloilo_routes_index.csv`\n",
        "        - `output/route_index_source.html`\n"
      ],
      "id": "60ca3744"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import re\n",
        "import time\n",
        "from datetime import datetime, timezone\n",
        "from pathlib import Path\n",
        "from urllib.parse import parse_qs, urljoin, urlparse\n",
        "\n",
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup, Tag\n",
        "\n",
        "BASE_URL = \"https://shemaegomez.com/iloilo-city-jeepney-routes/\"\n",
        "KML_URL_TEMPLATE = \"https://www.google.com/maps/d/kml?mid={mid}&forcekml=1\"\n",
        "OUTPUT_DIR = Path(\"output\")\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "HEADERS = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 \"\n",
        "    \"(KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36\"\n",
        "}\n"
      ],
      "id": "fb1ba619"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "response = requests.get(BASE_URL, headers=HEADERS, timeout=30)\n",
        "response.raise_for_status()\n",
        "\n",
        "if not response.encoding or response.encoding.lower() == \"iso-8859-1\":\n",
        "    response.encoding = response.apparent_encoding or \"utf-8\"\n",
        "\n",
        "html = response.text\n",
        "soup = BeautifulSoup(html, \"lxml\")\n",
        "article = soup.select_one(\"article .entry-content\") or soup.select_one(\".entry-content\") or soup\n",
        "\n",
        "(OUTPUT_DIR / \"route_index_source.html\").write_text(html, encoding=\"utf-8\")\n",
        "print(f\"Downloaded: {BASE_URL}\")\n"
      ],
      "id": "96f1506a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ROUTE_HEADER_PATTERN = re.compile(r\"^ROUTE\\s*#?\\s*(\\d+)\\b\", flags=re.IGNORECASE)\n",
        "\n",
        "def normalize_text(text: str) -> str:\n",
        "    if not text:\n",
        "        return \"\"\n",
        "    return \" \".join(text.replace(\"\\xa0\", \" \").split())\n",
        "\n",
        "def parse_route_number(text: str):\n",
        "    match = re.search(r\"\\bROUTE\\s*#?\\s*(\\d+)\\b\", text or \"\", flags=re.IGNORECASE)\n",
        "    return int(match.group(1)) if match else None\n",
        "\n",
        "def split_stops(description: str):\n",
        "    if not description:\n",
        "        return []\n",
        "    cleaned = description.replace(\";\", \",\")\n",
        "    stops = [normalize_text(part).strip(\" .\") for part in cleaned.split(\",\")]\n",
        "    return [stop for stop in stops if stop]\n",
        "\n",
        "def extract_mid_from_url(url: str):\n",
        "    if not url:\n",
        "        return None\n",
        "    parsed = urlparse(url)\n",
        "    query = parse_qs(parsed.query)\n",
        "    mids = query.get(\"mid\")\n",
        "    return mids[0] if mids else None\n",
        "\n",
        "def parse_kml_polylines(kml_text: str):\n",
        "    kml_soup = BeautifulSoup(kml_text, \"xml\")\n",
        "    polylines = []\n",
        "\n",
        "    for idx, placemark in enumerate(kml_soup.find_all(\"Placemark\"), start=1):\n",
        "        line = placemark.find(\"LineString\")\n",
        "        if not line:\n",
        "            continue\n",
        "\n",
        "        coordinates_tag = line.find(\"coordinates\")\n",
        "        if not coordinates_tag:\n",
        "            continue\n",
        "\n",
        "        coordinate_tokens = normalize_text(coordinates_tag.get_text(\" \", strip=True)).split()\n",
        "        coordinates_lng_lat = []\n",
        "        coordinates_lat_lng = []\n",
        "\n",
        "        for token in coordinate_tokens:\n",
        "            parts = token.split(\",\")\n",
        "            if len(parts) < 2:\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                lng = float(parts[0])\n",
        "                lat = float(parts[1])\n",
        "            except ValueError:\n",
        "                continue\n",
        "\n",
        "            coordinates_lng_lat.append([lng, lat])\n",
        "            coordinates_lat_lng.append([lat, lng])\n",
        "\n",
        "        if len(coordinates_lng_lat) < 2:\n",
        "            continue\n",
        "\n",
        "        name_tag = placemark.find(\"name\")\n",
        "        polyline_name = normalize_text(name_tag.get_text(\" \", strip=True)) if name_tag else f\"segment_{idx}\"\n",
        "\n",
        "        polylines.append(\n",
        "            {\n",
        "                \"name\": polyline_name,\n",
        "                \"point_count\": len(coordinates_lng_lat),\n",
        "                \"coordinates_lng_lat\": coordinates_lng_lat,\n",
        "                \"coordinates_lat_lng\": coordinates_lat_lng,\n",
        "            }\n",
        "        )\n",
        "\n",
        "    return polylines\n",
        "\n",
        "def fetch_map_geometry(map_mid: str, session: requests.Session, cache: dict):\n",
        "    if not map_mid:\n",
        "        return {\n",
        "            \"map_mid\": None,\n",
        "            \"map_kml_url\": None,\n",
        "            \"map_polylines\": [],\n",
        "            \"map_polyline_count\": 0,\n",
        "            \"map_point_count\": 0,\n",
        "            \"map_scrape_error\": None,\n",
        "        }\n",
        "\n",
        "    if map_mid in cache:\n",
        "        return cache[map_mid]\n",
        "\n",
        "    kml_url = KML_URL_TEMPLATE.format(mid=map_mid)\n",
        "    try:\n",
        "        kml_response = session.get(kml_url, headers=HEADERS, timeout=45)\n",
        "        kml_response.raise_for_status()\n",
        "        if not kml_response.encoding:\n",
        "            kml_response.encoding = \"utf-8\"\n",
        "\n",
        "        map_polylines = parse_kml_polylines(kml_response.text)\n",
        "        result = {\n",
        "            \"map_mid\": map_mid,\n",
        "            \"map_kml_url\": kml_url,\n",
        "            \"map_polylines\": map_polylines,\n",
        "            \"map_polyline_count\": len(map_polylines),\n",
        "            \"map_point_count\": sum(polyline[\"point_count\"] for polyline in map_polylines),\n",
        "            \"map_scrape_error\": None,\n",
        "        }\n",
        "    except Exception as exc:\n",
        "        result = {\n",
        "            \"map_mid\": map_mid,\n",
        "            \"map_kml_url\": kml_url,\n",
        "            \"map_polylines\": [],\n",
        "            \"map_polyline_count\": 0,\n",
        "            \"map_point_count\": 0,\n",
        "            \"map_scrape_error\": str(exc),\n",
        "        }\n",
        "\n",
        "    cache[map_mid] = result\n",
        "    time.sleep(0.35)\n",
        "    return result\n"
      ],
      "id": "56ad5ce5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "table_rows = []\n",
        "\n",
        "compilation_heading = article.find(\n",
        "    lambda t: t.name in {\"h2\", \"h3\"}\n",
        "    and \"jeepney routes compilation\" in normalize_text(t.get_text(\" \", strip=True)).lower()\n",
        ")\n",
        "\n",
        "table = compilation_heading.find_next(\"table\") if compilation_heading else None\n",
        "if table:\n",
        "    for tr in table.select(\"tr\"):\n",
        "        cells = tr.find_all(\"td\")\n",
        "        if not cells:\n",
        "            continue\n",
        "\n",
        "        route_title = normalize_text(cells[0].get_text(\" \", strip=True))\n",
        "        if not route_title or route_title.lower().startswith(\"route names\"):\n",
        "            continue\n",
        "\n",
        "        route_anchor = cells[0].find(\"a\", href=True)\n",
        "        guide_anchor = cells[1].find(\"a\", href=True) if len(cells) > 1 else None\n",
        "\n",
        "        table_rows.append(\n",
        "            {\n",
        "                \"route_number\": parse_route_number(route_title),\n",
        "                \"route_title\": route_title,\n",
        "                \"route_link\": urljoin(BASE_URL, route_anchor[\"href\"]) if route_anchor else None,\n",
        "                \"full_guide_url\": urljoin(BASE_URL, guide_anchor[\"href\"]) if guide_anchor else None,\n",
        "                \"is_outside_iloilo_city\": route_title.lower().startswith(\"outside iloilo city\"),\n",
        "            }\n",
        "        )\n",
        "\n",
        "print(f\"Compilation table rows captured: {len(table_rows)}\")\n"
      ],
      "id": "32b35ff5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "routes = []\n",
        "table_guide_lookup = {\n",
        "    row[\"route_number\"]: row[\"full_guide_url\"]\n",
        "    for row in table_rows\n",
        "    if row.get(\"route_number\") is not None and row.get(\"full_guide_url\")\n",
        "}\n",
        "\n",
        "session = requests.Session()\n",
        "map_cache = {}\n",
        "\n",
        "for h2 in article.find_all(\"h2\", class_=\"wp-block-heading\"):\n",
        "    route_title = normalize_text(h2.get_text(\" \", strip=True))\n",
        "    if not ROUTE_HEADER_PATTERN.match(route_title):\n",
        "        continue\n",
        "\n",
        "    route_data = {\n",
        "        \"route_number\": parse_route_number(route_title),\n",
        "        \"route_title\": route_title,\n",
        "        \"section_id\": h2.get(\"id\"),\n",
        "        \"source_url\": BASE_URL,\n",
        "        \"stop_description\": None,\n",
        "        \"stops\": [],\n",
        "        \"full_guide_url\": None,\n",
        "        \"map_embed_url\": None,\n",
        "        \"map_mid\": None,\n",
        "        \"map_kml_url\": None,\n",
        "        \"map_polylines\": [],\n",
        "        \"map_polyline_count\": 0,\n",
        "        \"map_point_count\": 0,\n",
        "        \"map_scrape_error\": None,\n",
        "        \"faq_url\": None,\n",
        "    }\n",
        "\n",
        "    node = h2.next_sibling\n",
        "    while node:\n",
        "        if isinstance(node, Tag):\n",
        "            if node.name == \"h2\":\n",
        "                next_title = normalize_text(node.get_text(\" \", strip=True))\n",
        "                if ROUTE_HEADER_PATTERN.match(next_title):\n",
        "                    break\n",
        "\n",
        "            if not route_data[\"full_guide_url\"] and node.name in {\"p\", \"h3\", \"h4\"}:\n",
        "                node_text = normalize_text(node.get_text(\" \", strip=True)).lower()\n",
        "                if \"full guide\" in node_text:\n",
        "                    anchor = node.find(\"a\", href=True)\n",
        "                    if anchor:\n",
        "                        route_data[\"full_guide_url\"] = urljoin(BASE_URL, anchor[\"href\"])\n",
        "\n",
        "            if node.name == \"p\":\n",
        "                paragraph_text = normalize_text(node.get_text(\" \", strip=True))\n",
        "                lowered = paragraph_text.lower()\n",
        "\n",
        "                if paragraph_text and not lowered.startswith(\"full guide\") and not lowered.startswith(\"read also\") and not route_data[\"stop_description\"]:\n",
        "                    route_data[\"stop_description\"] = paragraph_text\n",
        "\n",
        "            iframe = node.find(\"iframe\", src=True)\n",
        "            if iframe and not route_data[\"map_embed_url\"]:\n",
        "                route_data[\"map_embed_url\"] = urljoin(BASE_URL, iframe[\"src\"])\n",
        "\n",
        "            if node.name in {\"h4\", \"p\"}:\n",
        "                node_text = normalize_text(node.get_text(\" \", strip=True)).lower()\n",
        "                if \"faq\" in node_text and not route_data[\"faq_url\"]:\n",
        "                    faq_anchor = node.find(\"a\", href=True)\n",
        "                    if faq_anchor:\n",
        "                        route_data[\"faq_url\"] = urljoin(BASE_URL, faq_anchor[\"href\"])\n",
        "\n",
        "        node = node.next_sibling\n",
        "\n",
        "    if not route_data[\"full_guide_url\"] and route_data[\"route_number\"] in table_guide_lookup:\n",
        "        route_data[\"full_guide_url\"] = table_guide_lookup[route_data[\"route_number\"]]\n",
        "\n",
        "    if route_data[\"map_embed_url\"]:\n",
        "        map_mid = extract_mid_from_url(route_data[\"map_embed_url\"])\n",
        "        route_data.update(fetch_map_geometry(map_mid, session=session, cache=map_cache))\n",
        "\n",
        "    route_data[\"stops\"] = split_stops(route_data[\"stop_description\"])\n",
        "    routes.append(route_data)\n",
        "\n",
        "session.close()\n",
        "\n",
        "routes.sort(key=lambda row: (row[\"route_number\"] is None, row[\"route_number\"] or 9999))\n",
        "print(f\"Route sections scraped: {len(routes)}\")\n",
        "print(f\"Routes with extracted polylines: {sum(1 for r in routes if r['map_polyline_count'] > 0)}\")\n"
      ],
      "id": "4b6a555a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output_payload = {\n",
        "    \"source_url\": BASE_URL,\n",
        "    \"scraped_at_utc\": datetime.now(timezone.utc).isoformat(),\n",
        "    \"route_count\": len(routes),\n",
        "    \"routes_with_geometry\": sum(1 for route in routes if route.get(\"map_polyline_count\", 0) > 0),\n",
        "    \"total_polyline_segments\": sum(route.get(\"map_polyline_count\", 0) for route in routes),\n",
        "    \"total_polyline_points\": sum(route.get(\"map_point_count\", 0) for route in routes),\n",
        "    \"routes\": routes,\n",
        "    \"compilation_table_rows\": table_rows,\n",
        "}\n",
        "\n",
        "json_path = OUTPUT_DIR / \"iloilo_routes_index.json\"\n",
        "json_path.write_text(json.dumps(output_payload, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n",
        "\n",
        "csv_rows = []\n",
        "for route in routes:\n",
        "    csv_rows.append(\n",
        "        {\n",
        "            \"route_number\": route[\"route_number\"],\n",
        "            \"route_title\": route[\"route_title\"],\n",
        "            \"section_id\": route[\"section_id\"],\n",
        "            \"full_guide_url\": route[\"full_guide_url\"],\n",
        "            \"map_embed_url\": route[\"map_embed_url\"],\n",
        "            \"map_mid\": route[\"map_mid\"],\n",
        "            \"map_kml_url\": route[\"map_kml_url\"],\n",
        "            \"map_polyline_count\": route[\"map_polyline_count\"],\n",
        "            \"map_point_count\": route[\"map_point_count\"],\n",
        "            \"map_scrape_error\": route[\"map_scrape_error\"],\n",
        "            \"faq_url\": route[\"faq_url\"],\n",
        "            \"stop_description\": route[\"stop_description\"],\n",
        "            \"stops_pipe_delimited\": \" | \".join(route[\"stops\"]),\n",
        "            \"stop_count\": len(route[\"stops\"]),\n",
        "        }\n",
        "    )\n",
        "\n",
        "pd.DataFrame(csv_rows).to_csv(OUTPUT_DIR / \"iloilo_routes_index.csv\", index=False, encoding=\"utf-8\")\n",
        "\n",
        "features = []\n",
        "for route in routes:\n",
        "    for segment_index, polyline in enumerate(route.get(\"map_polylines\", []), start=1):\n",
        "        if len(polyline.get(\"coordinates_lng_lat\", [])) < 2:\n",
        "            continue\n",
        "        features.append(\n",
        "            {\n",
        "                \"type\": \"Feature\",\n",
        "                \"properties\": {\n",
        "                    \"route_number\": route.get(\"route_number\"),\n",
        "                    \"route_title\": route.get(\"route_title\"),\n",
        "                    \"map_mid\": route.get(\"map_mid\"),\n",
        "                    \"segment_index\": segment_index,\n",
        "                    \"segment_name\": polyline.get(\"name\"),\n",
        "                    \"point_count\": polyline.get(\"point_count\"),\n",
        "                },\n",
        "                \"geometry\": {\n",
        "                    \"type\": \"LineString\",\n",
        "                    \"coordinates\": polyline.get(\"coordinates_lng_lat\", []),\n",
        "                },\n",
        "            }\n",
        "        )\n",
        "\n",
        "geojson_payload = {\"type\": \"FeatureCollection\", \"features\": features}\n",
        "geojson_path = OUTPUT_DIR / \"iloilo_route_polylines.geojson\"\n",
        "geojson_path.write_text(json.dumps(geojson_payload, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n",
        "\n",
        "print(f\"Saved: {json_path}\")\n",
        "print(\"Saved: output/iloilo_routes_index.csv\")\n",
        "print(f\"Saved: {geojson_path}\")\n"
      ],
      "id": "25f7d8ac"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pd.DataFrame(\n",
        "    [\n",
        "        {\n",
        "            \"route_number\": r[\"route_number\"],\n",
        "            \"route_title\": r[\"route_title\"],\n",
        "            \"stop_count\": len(r[\"stops\"]),\n",
        "            \"has_map\": bool(r[\"map_embed_url\"]),\n",
        "            \"polyline_segments\": r[\"map_polyline_count\"],\n",
        "            \"polyline_points\": r[\"map_point_count\"],\n",
        "            \"has_full_guide\": bool(r[\"full_guide_url\"]),\n",
        "        }\n",
        "        for r in routes\n",
        "    ]\n",
        ").head(15)\n"
      ],
      "id": "32d46530"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}